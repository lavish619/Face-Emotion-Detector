{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydot\n",
    "import cv2\n",
    "from data_loader import load_dataset\n",
    "from models import load_trial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facial-expressions_2868585k.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facial-expressions_2868584k.jpg</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facial-expressions_2868582k.jpg</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron_Eckhart_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron_Guiel_0001.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13684</th>\n",
       "      <td>SharmilaTagore_80.jpg</td>\n",
       "      <td>HAPPINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13685</th>\n",
       "      <td>SharmilaTagore_81.jpg</td>\n",
       "      <td>HAPPINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13686</th>\n",
       "      <td>SharmilaTagore_82.jpg</td>\n",
       "      <td>HAPPINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>SharmilaTagore_83.jpg</td>\n",
       "      <td>HAPPINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>SharmilaTagore_9.jpg</td>\n",
       "      <td>HAPPINESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13689 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image    emotion\n",
       "0      facial-expressions_2868585k.jpg   surprise\n",
       "1      facial-expressions_2868584k.jpg    disgust\n",
       "2      facial-expressions_2868582k.jpg       fear\n",
       "3               Aaron_Eckhart_0001.jpg    neutral\n",
       "4                 Aaron_Guiel_0001.jpg  happiness\n",
       "...                                ...        ...\n",
       "13684            SharmilaTagore_80.jpg  HAPPINESS\n",
       "13685            SharmilaTagore_81.jpg  HAPPINESS\n",
       "13686            SharmilaTagore_82.jpg  HAPPINESS\n",
       "13687            SharmilaTagore_83.jpg  HAPPINESS\n",
       "13688             SharmilaTagore_9.jpg  HAPPINESS\n",
       "\n",
       "[13689 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      6717\n",
       "happiness    5309\n",
       "HAPPINESS     387\n",
       "surprise      356\n",
       "anger         227\n",
       "DISGUST       195\n",
       "NEUTRAL       151\n",
       "SADNESS       144\n",
       "sadness       124\n",
       "ANGER          24\n",
       "disgust        13\n",
       "fear           13\n",
       "SURPRISE       12\n",
       "contempt        9\n",
       "FEAR            8\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      6868\n",
       "happiness    5696\n",
       "surprise      368\n",
       "sadness       268\n",
       "anger         251\n",
       "disgust       208\n",
       "fear           21\n",
       "contempt        9\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing emotion in capital to small\n",
    "dataset['emotion'] = dataset['emotion'].replace({'NEUTRAL':'neutral','HAPPINESS':'happiness','DISGUST':'disgust',\n",
    "                                                 'SADNESS':'sadness','ANGER':'anger','SURPRISE':'surprise',\n",
    "                                                 'FEAR':'fear'})\n",
    "\n",
    "num_outputs = len(dataset[\"emotion\"].value_counts()) #number of classes\n",
    "dataset[\"emotion\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset['image'], dataset['emotion'])\n",
    "\n",
    "train_data = pd.concat([x_train, y_train],axis = 1)  #training dataframe\n",
    "test_data = pd.concat([x_test, y_test],axis = 1)  #test dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8213 validated image filenames belonging to 8 classes.\n",
      "Found 2053 validated image filenames belonging to 8 classes.\n",
      "Found 3423 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split = 0.2) # rescaling the pixel values between 0 to 1.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # rescaling the pixel values between 0 to 1.\n",
    "\n",
    "#Access training images from directory marked to their class labels in dataframe\n",
    "train_generator = datagen.flow_from_dataframe(dataframe = train_data,\n",
    "                                              directory= \"./facial_expressions/images\",\n",
    "                                              x_col=\"image\", y_col = \"emotion\",\n",
    "                                              target_size = (350,350),\n",
    "                                              subset = \"training\")  \n",
    "\n",
    "#Access validation images from directory marked to their class labels in dataframe\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe = train_data,\n",
    "                                                   directory= \"./facial_expressions/images\",\n",
    "                                                   x_col=\"image\", y_col = \"emotion\",\n",
    "                                                   target_size = (350,350),\n",
    "                                                   subset= \"validation\")\n",
    "\n",
    "#Access test images from directory marked to their class labels in dataframe\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe = test_data,\n",
    "                                                  directory= \"./facial_expressions/images\",\n",
    "                                                  x_col=\"image\", y_col = \"emotion\",\n",
    "                                                  target_size = (350,350))\n",
    "\n",
    "#traget size is chosen (350,350) because maximum images have this dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'happiness': 4,\n",
       " 'neutral': 5,\n",
       " 'sadness': 6,\n",
       " 'surprise': 7}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices = train_generator.class_indices #get indices of each class in one hot encoding done during flow from dataframe\n",
    "label_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trial_model((350,350,3), num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 173, 173, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 173, 173, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 173, 173, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 41, 41, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 41, 41, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 41, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               13107712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 13,165,896\n",
      "Trainable params: 13,165,704\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 4.0940 - accuracy: 0.5903 - val_loss: 2.0174 - val_accuracy: 0.4759\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 1.2493 - accuracy: 0.6644 - val_loss: 2.7186 - val_accuracy: 0.4384\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 1.0965 - accuracy: 0.6883 - val_loss: 0.7652 - val_accuracy: 0.7350\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 0.7875 - accuracy: 0.7291 - val_loss: 0.7741 - val_accuracy: 0.7613\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 0.6569 - accuracy: 0.7681 - val_loss: 0.8314 - val_accuracy: 0.6985\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.6351 - accuracy: 0.7756 - val_loss: 0.7930 - val_accuracy: 0.7038\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 0.6442 - accuracy: 0.7745 - val_loss: 0.7665 - val_accuracy: 0.6946\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 0.5793 - accuracy: 0.7921 - val_loss: 0.6840 - val_accuracy: 0.7662\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 91s 905ms/step - loss: 0.5355 - accuracy: 0.8031 - val_loss: 0.7436 - val_accuracy: 0.7457\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.5341 - accuracy: 0.8078 - val_loss: 0.6630 - val_accuracy: 0.7638\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.5223 - accuracy: 0.8081 - val_loss: 0.5863 - val_accuracy: 0.7949\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.4730 - accuracy: 0.8309 - val_loss: 0.5867 - val_accuracy: 0.8018\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.4671 - accuracy: 0.8304 - val_loss: 0.6984 - val_accuracy: 0.7399\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.4511 - accuracy: 0.8356 - val_loss: 0.7207 - val_accuracy: 0.7745\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.4392 - accuracy: 0.8481 - val_loss: 0.6841 - val_accuracy: 0.7735\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.4141 - accuracy: 0.8456 - val_loss: 0.9965 - val_accuracy: 0.6503\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.4146 - accuracy: 0.8482 - val_loss: 0.6646 - val_accuracy: 0.7769\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.3624 - accuracy: 0.8674 - val_loss: 0.7509 - val_accuracy: 0.7443\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.3462 - accuracy: 0.8741 - val_loss: 0.6027 - val_accuracy: 0.8105\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.3297 - accuracy: 0.8808 - val_loss: 0.6352 - val_accuracy: 0.7906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x193b8c724c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          epochs = 20,\n",
    "          validation_data = validation_generator\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 13s 122ms/step - loss: 0.6344 - accuracy: 0.7894\n",
      "Accuracy on test set: 0.7893660664558411\n"
     ]
    }
   ],
   "source": [
    "pred = model.evaluate(test_generator)\n",
    "print(\"Accuracy on test set:\", pred[1])\n",
    "#print(np.argmax(model.predict(test_generator),axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"trial_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
